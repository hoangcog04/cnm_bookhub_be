import os
import json
import re
import time
import random
from dotenv import load_dotenv
from google import genai # Th∆∞ vi·ªán m·ªõi
from google.genai import types # ƒê·ªÉ config
from google.api_core import exceptions
from cnm_bookhub_be.ai.models import SearchState

load_dotenv()

# --- 1. SETUP XOAY V√íNG KEY ---
api_keys_str = os.getenv("GEMINI_API_KEYS", "") # L·∫•y list key ngƒÉn c√°ch b·ªüi d·∫•u ph·∫©y
API_KEYS = api_keys_str.split(",") if api_keys_str else []

# Fallback n·∫øu ch·ªâ c√≥ 1 key l·∫ª
if not API_KEYS:
    single_key = os.getenv("GEMINI_API_KEY")
    if single_key:
        API_KEYS = [single_key]

print(f"üîë ƒê√£ t·∫£i {len(API_KEYS)} API Key. S·∫µn s√†ng xoay v√≤ng!")

current_key_index = 0
MODEL_NAME = 'gemini-3-flash-preview'

# Bi·∫øn global client ƒë·ªÉ d√πng chung (s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t khi ƒë·ªïi key)
client = None

def get_current_client():
    """H√†m l·∫•y client hi·ªán t·∫°i ho·∫∑c kh·ªüi t·∫°o n·∫øu ch∆∞a c√≥"""
    global client, current_key_index
    if client is None:
        if not API_KEYS:
            raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y API Key n√†o trong .env!")
        client = genai.Client(api_key=API_KEYS[current_key_index])
    return client

def switch_next_key():
    """H√†m chuy·ªÉn sang key ti·∫øp theo"""
    global client, current_key_index
    current_key_index = (current_key_index + 1) % len(API_KEYS)
    print(f"üîÑ ƒê·ªïi sang Key #{current_key_index + 1}...")
    # Kh·ªüi t·∫°o l·∫°i client v·ªõi key m·ªõi
    client = genai.Client(api_key=API_KEYS[current_key_index])


# --- 2. H√ÄM G·ªåI GEMINI TH√îNG MINH (C√ö PH√ÅP M·ªöI + ASYNC) ---
async def call_gemini_smart(prompt: str, response_json=False):
    global client
    
    # Th·ª≠ t·ªëi ƒëa s·ªë l·∫ßn b·∫±ng s·ªë l∆∞·ª£ng key ƒëang c√≥
    for attempt in range(len(API_KEYS)):
        try:
            active_client = get_current_client()
            
            # C·∫•u h√¨nh tr·∫£ v·ªÅ JSON ho·∫∑c Text
            config = types.GenerateContentConfig(
                temperature=0.5,
                response_mime_type="application/json" if response_json else "text/plain"
            )

            # G·ªçi Async (aio) ƒë·ªÉ kh√¥ng ch·∫∑n server
            response = await active_client.aio.models.generate_content(
                model=MODEL_NAME,
                contents=prompt,
                config=config
            )
            return response.text
            
        except Exception as e:
            # Ki·ªÉm tra l·ªói Quota (429 Resource Exhausted)
            # L∆∞u √Ω: Th∆∞ vi·ªán m·ªõi ƒë√¥i khi n√©m l·ªói kh√°c nhau, n√™n check chu·ªói l·ªói cho ch·∫Øc
            error_str = str(e).lower()
            if "429" in error_str or "quota" in error_str or "exhausted" in error_str:
                print(f"‚ö†Ô∏è Key #{current_key_index + 1} ƒë√£ h·∫øt h·∫°n m·ª©c! ƒêang ƒë·ªïi Key kh√°c...")
                switch_next_key()
                time.sleep(1) # Ngh·ªâ 1 x√≠u r·ªìi retry
                continue # Th·ª≠ l·∫°i v√≤ng l·∫∑p v·ªõi key m·ªõi
            else:
                print(f"‚ùå L·ªói Gemini (Kh√¥ng ph·∫£i do quota): {e}")
                raise e # L·ªói kh√°c th√¨ b·∫Øn ra lu√¥n

    raise Exception("‚ùå T·∫•t c·∫£ API Key ƒë·ªÅu ƒë√£ h·∫øt h·∫°n m·ª©c!")


# --- 3. H√ÄM EXTRACT INTENT ---
async def extract_intent(current_state: SearchState, user_msg: str, valid_categories: list) -> SearchState:    
    categories_str = ", ".join([f'"{c}"' for c in valid_categories])

    prompt = f"""
    B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh qu·∫£n l√Ω b·ªô l·ªçc t√¨m ki·∫øm s√°ch cho h·ªá th·ªëng BookHub.
    
    1. INPUT:
    - State hi·ªán t·∫°i: {current_state.model_dump_json()}
    - User n√≥i: "{user_msg}"
    - DANH S√ÅCH CH·ª¶ ƒê·ªÄ C√ì TRONG KHO (DB): [{categories_str}]

    2. NHI·ªÜM V·ª§: Ph√¢n t√≠ch v√† Update state JSON.
    
    A. X·ª¨ L√ù T√äN S√ÅCH:
       - N·∫øu user nh·∫Øc t√™n s√°ch c·ª• th·ªÉ -> Update "book_name".
       - N·∫øu ƒë·ªïi s√°ch -> Update "book_name" m·ªõi.

    B. X·ª¨ L√ù S·ªê L∆Ø·ª¢NG:
       - C√≥ s·ªë c·ª• th·ªÉ -> Update quantity.
       - KH√îNG nh·∫Øc s·ªë -> Reset quantity = 3.

    C. X·ª¨ L√ù NG·ªÆ C·∫¢NH (CONTEXT):
       - User h·ªèi T√äN S√ÅCH m·ªõi ho·∫∑c TH·ªÇ LO·∫†I m·ªõi -> Reset c√°c tr∆∞·ªùng c≈©.
       - User ch·ªâ h·ªèi GI√Å/T√çNH CH·∫§T (r·∫ª, hay...) -> Gi·ªØ nguy√™n context.

    D. X·ª¨ L√ù GI√Å:
       - "gi√° sinh vi√™n", "r·∫ª" -> max_price = 100000.
       - S·ªë c·ª• th·ªÉ (d∆∞·ªõi 200k) -> max_price = 200000.
       
    E. CHU·∫®N H√ìA T√äN: S·ª≠a l·ªói ch√≠nh t·∫£ t√™n s√°ch/t√°c gi·∫£.

    F. X·ª¨ L√ù CATEGORY:
       - Ch·ªâ ƒëi·ªÅn 'category' n·∫øu kh·ªõp (ho·∫∑c ƒë·ªìng nghƒ©a) v·ªõi danh s√°ch [{categories_str}].
       - Map t·ª´ ƒë·ªìng nghƒ©a v·ªÅ t√™n chu·∫©n.
       - Kh√¥ng kh·ªõp -> null.

    3. OUTPUT JSON M·∫™U:
    {{ "query": "...", "book_name": "Nh√† Gi·∫£ Kim", "author": null, "category": "L√£ng m·∫°n", "min_price": null, "max_price": null, "quantity": 3 }}
    """

    try:
        # G·ªçi h√†m smart v·ªõi ch·∫ø ƒë·ªô JSON=True
        text_response = await call_gemini_smart(prompt, response_json=True)
        
        # Clean data (ph√≤ng h·ªù)
        text_response = text_response.strip()
        if text_response.startswith("```"):
            text_response = re.sub(r"^```json|^```|```$", "", text_response).strip()
            
        data = json.loads(text_response)
        return SearchState(**data)
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói AI Extract Intent: {e}")
        # Tr·∫£ v·ªÅ state c≈© thay v√¨ crash
        return current_state


# --- 4. H√ÄM GENERATE RESPONSE ---
async def generate_chat_response(user_msg: str, found_books: list, has_greeted: bool) -> str:
    
    if not found_books:
        return "Ti·∫øc qu√°, m√¨nh t√¨m theo y√™u c·∫ßu c·ªßa b·∫°n th√¨ ch∆∞a th·∫•y cu·ªën n√†o ph√π h·ª£p trong kho. B·∫°n th·ª≠ n·ªõi r·ªông kho·∫£ng gi√° ho·∫∑c t√¨m ch·ªß ƒë·ªÅ kh√°c xem sao nh√©?"

    context_text = ""
    for i, book in enumerate(found_books, 1):
        price_str = "{:,}".format(book['price'])
        context_text += f"{i}. {book['title']} - Gi√°: {price_str}ƒë - T√°c gi·∫£: {book['author']}\n"

    if not has_greeted:
        tone_instruction = "- ƒê√¢y l√† l·∫ßn ƒë·∫ßu g·∫∑p kh√°ch: H√£y B·∫ÆT ƒê·∫¶U b·∫±ng l·ªùi ch√†o th√¢n thi·ªán (VD: Ch√†o b·∫°n, BookHub xin ch√†o...)."
    else:
        tone_instruction = "- ƒê√¢y l√† ƒëo·∫°n chat ti·∫øp theo: TUY·ªÜT ƒê·ªêI KH√îNG ch√†o l·∫°i (Kh√¥ng n√≥i 'Ch√†o b·∫°n' n·ªØa). H√£y ƒëi th·∫≥ng v√†o c√¢u tr·∫£ l·ªùi ho·∫∑c nh·∫≠n x√©t v·ªÅ s√°ch."
        
    prompt = f"""
    B·∫°n l√† nh√¢n vi√™n b√°n s√°ch th√¥ng minh, th√¢n thi·ªán.
    
    TH√îNG TIN ƒê·∫¶U V√ÄO:
    1. KH√ÅCH H·ªéI: "{user_msg}"
    2. K·∫æT QU·∫¢ T√åM KI·∫æM ({len(found_books)} cu·ªën):
    {context_text}
    
    NHI·ªÜM V·ª§:
    - N·∫øu s√°ch KH·ªöP: Gi·ªõi thi·ªáu nhi·ªát t√¨nh.
    - N·∫øu s√°ch G·∫¶N GI·ªêNG (Sai ch√≠nh t·∫£): M·∫°nh d·∫°n g·ª£i √Ω "C√≥ ph·∫£i √Ω b·∫°n l√†...".
    - N·∫øu s√°ch KH√ÅC (G·ª£i √Ω thay th·∫ø): N√≥i "Hi·ªán ch∆∞a c√≥ cu·ªën ƒë√≥, nh∆∞ng m√¨nh c√≥ cu·ªën n√†y hay l·∫Øm...".

    Y√äU C·∫¶U:
    - Gi·ªçng vƒÉn th√¢n thi·ªán, ng·∫Øn g·ªçn.
    - KH√îNG hi·ªÉn th·ªã JSON, ch·ªâ tr·∫£ v·ªÅ l·ªùi tho·∫°i.
    """
    
    try:
        # G·ªçi h√†m smart v·ªõi ch·∫ø ƒë·ªô JSON=False (Text)
        return await call_gemini_smart(prompt, response_json=False)
    except Exception as e:
        print(f"L·ªói generate response: {e}")
        return "H·ªá th·ªëng ƒëang b·∫≠n, nh∆∞ng b·∫°n xem danh s√°ch s√°ch b√™n d∆∞·ªõi nh√©!"